# @package _global_

defaults:
  - _self_
  - /data: lits.yaml
  - /model: vae/vq_vae_module.yaml
  - /paths: default.yaml

task_name: "reconstruction_metrics_lits"
tags: ["evaluation", "reconstruction", "metrics"]
seed: 12345

data:
  batch_size: 16  # Adjust for GPU memory (LiTS has 1 channel, can use larger batch)
  num_workers: 4
  image_size: 256
  full_dataset: false  # Use only healthy data for reconstruction evaluation

model:
  # Use LiTS VQ-VAE checkpoint paths
  encoder_path: /home/tqlong/qtung/gen-model-boilerplate/src/ckpt_lits/vq_vae/encoder.pth
  decoder_path: /home/tqlong/qtung/gen-model-boilerplate/src/ckpt_lits/vq_vae/decoder.pth
  vq_layer_path: /home/tqlong/qtung/gen-model-boilerplate/src/ckpt_lits/vq_vae/vq_layer_1024.pth
  
  net:
    encoder:
      in_channels: 1  # 1 channel for LiTS grayscale images
    decoder:
      out_channels: 1  # 1 channel output
    latent_dims: [1, 64, 64]  # Match LiTS VQ-VAE configuration
    vq_layer:
      embedding_dim: 1  # Match latent_dims[0]

# Evaluation settings
evaluation:
  max_batches: 100  # Limit for faster evaluation, set to -1 for full dataset
  save_dir: results/reconstruction_metrics/lits
  device: cuda
  lpips_network: alex  # Options: alex, vgg, squeeze
  save_visuals: true   # save original vs reconstructed image grids
  max_visuals: 16      # number of batches to visualize