task_name: sample_ldm
tags:
- inference
- sampling
seed: 12345
data:
  batch_size: 1
  num_workers: 8
  image_size: 256
  transform_train:
    _target_: albumentations.Compose
    transforms:
    - _target_: albumentations.Resize
      height: ${data.image_size}
      width: ${data.image_size}
      always_apply: true
    - _target_: albumentations.HorizontalFlip
      p: 0.5
    - _target_: albumentations.Normalize
      mean: 0.5
      std: 0.5
      max_pixel_value: 1.0
    - _target_: albumentations.pytorch.transforms.ToTensorV2
    additional_targets:
      cond: image
  transform_val:
    _target_: albumentations.Compose
    transforms:
    - _target_: albumentations.Resize
      height: ${data.image_size}
      width: ${data.image_size}
      always_apply: true
    - _target_: albumentations.Normalize
      mean: 0.5
      std: 0.5
      max_pixel_value: 1.0
    - _target_: albumentations.pytorch.transforms.ToTensorV2
    additional_targets:
      cond: image
  _target_: src.data.BraTSDataModule
  data_dir: /data/hpc/qtung/data/
  train_val_test_dir:
  - train
  - val
  - test
  pin_memory: true
  dataset_name: brats2020
  n_classes: -1
classifier:
  use_classifier: true
  path: /data/hpc/qtung/gen-model-boilerplate/src/ckpt_s256/classifier/classifier_ldm64_1000step.pth
  scale: 100.0
  use_label: true
sampling:
  num_samples: 25
  save_dir: /data/hpc/qtung/gen-model-boilerplate/results/inference_comparison
  noise_level: 200
  skip_normal: true
model:
  _target_: src.models.diffusion.LatentDiffusionModule
  use_ema: true
  num_timesteps: 1000
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 0.0001
    weight_decay: 1.0e-05
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    T_max: 100
    eta_min: 1.0e-07
  vae_net_path: None
  encoder_path: ${paths.root_dir}/src/ckpt_s256/vq_vae/encoder.pth
  decoder_path: ${paths.root_dir}/src/ckpt_s256/vq_vae/decoder.pth
  vq_layer_path: ${paths.root_dir}/src/ckpt_s256/vq_vae/vq_layer_1024.pth
  model_path: ${paths.root_dir}/src/ckpt_s256/latent_diffusion/unet_ldm64_1000step.pth
  vae:
    _target_: src.models.vae.net.VQVAE
    encoder:
      _target_: src.models.components.up_down.Encoder
      in_channels: 4
      z_channels: ${model.vae.latent_dims[0]}
      base_channels: 64
      block: Residual
      n_layer_blocks: 1
      drop_rate: 0.0
      channel_multipliers:
      - 1
      - 2
      - 4
      attention: Attention
      n_attention_heads: null
      n_attention_layers: null
      double_z: false
    decoder:
      _target_: src.models.components.up_down.Decoder
      out_channels: ${model.vae.encoder.in_channels}
      z_channels: ${model.vae.latent_dims[0]}
      base_channels: ${model.vae.encoder.base_channels}
      block: ${model.vae.encoder.block}
      n_layer_blocks: ${model.vae.encoder.n_layer_blocks}
      drop_rate: ${model.vae.encoder.drop_rate}
      channel_multipliers: ${model.vae.encoder.channel_multipliers}
      attention: ${model.vae.encoder.attention}
      n_attention_heads: ${model.vae.encoder.n_attention_heads}
      n_attention_layers: ${model.vae.encoder.n_attention_layers}
    latent_dims:
    - 4
    - 64
    - 64
    vq_layer:
      _target_: src.models.vae.net.VectorQuantizer
      num_embeddings: 1024
      embedding_dim: ${model.vae.latent_dims[0]}
      beta: 0.25
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${paths.root_dir}/data/
  log_dir: ${paths.root_dir}/logs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
